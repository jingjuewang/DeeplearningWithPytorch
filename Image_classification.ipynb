{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  invasive\n",
       "0  train/1.jpg         0\n",
       "1  train/2.jpg         0\n",
       "2  train/3.jpg         1\n",
       "3  train/4.jpg         0\n",
       "4  train/5.jpg         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_train(path):\n",
    "    train_set = pd.read_csv('train_labels.csv')\n",
    "    train_label = np.array(train_set['invasive'].iloc[: ])\n",
    "    train_files = []\n",
    "    for i in range(len(train_set)):\n",
    "        train_files.append(path + str(int(train_set.iloc[i][0])) +'.jpg')\n",
    "    train_set['name'] = train_files\n",
    "    return train_files, train_set, train_label\n",
    "\n",
    "train_files, train_set, train_label = load_train(\"train/\")\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    test_set = pd.read_csv('sample_submission.csv')\n",
    "    test_files = []\n",
    "    for i in range(len(test_set)):\n",
    "        test_files.append(path + str(int(test_set.iloc[i][0])) +'.jpg')\n",
    "    test_set[\"name\"] = test_files\n",
    "    return test_files, test_set\n",
    "\n",
    "test_files, test_set = load_test(\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        with Image.open(f) as img_f:\n",
    "            return img_f.convert('RGB').resize((320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, training=True, validating=False, transforms=None):\n",
    "        if training:\n",
    "            df = df.sample(frac=1)\n",
    "            split_index = int(df.shape[0] * 0.8)\n",
    "            if validating:\n",
    "                split_data = df.values[split_index:]\n",
    "            else:\n",
    "                split_data = df.values[:split_index]\n",
    "            imgs = [None] * split_data.shape[0]\n",
    "            labels = [None] * split_data.shape[0]\n",
    "            for i, row in enumerate(split_data):\n",
    "                fn, labels[i] = row\n",
    "                imgs[i] = load_img(fn)\n",
    "        else:\n",
    "            imgs = [None]*df.values.shape[0]\n",
    "            for i, row in enumerate(df.values):\n",
    "                fn, _ = row\n",
    "                imgs[i] = load_img(fn)\n",
    "        self.imgs = imgs\n",
    "        self.training = training\n",
    "        self.transforms = transforms\n",
    "        self.num = len(imgs)\n",
    "        if self.training:\n",
    "            self.labels = np.array(labels, dtype=np.float32)\n",
    "                 \n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.transforms(self.imgs[idx])\n",
    "        if self.training:\n",
    "            img = self.transforms(self.imgs[idx])\n",
    "            return img, self.labels[idx]\n",
    "        else:\n",
    "            return img\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py:563: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Scale(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, training=True, validating=False, shuffle=True):\n",
    "    if training and not validating:\n",
    "        transkey = 'train'\n",
    "    else:\n",
    "        transkey = 'test'\n",
    "    ds = MyDataset(dataset, training=training, validating=validating, transforms=data_transforms[transkey])\n",
    "    loader = DataLoader(ds, batch_size=10, shuffle=shuffle)\n",
    "    loader.num = ds.num\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(net, lr=0.01):\n",
    "    parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    optimizer = torch.optim.SGD(parameters, lr=lr, momentum=0.9)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_file = 'best_model.pth'\n",
    "def train(net, criterion, optimizer, epochs=5):\n",
    "    data_loaders = {'train': get_data_loader(train_set), \n",
    "                    'valid': get_data_loader(train_set, validating=True)}\n",
    "    best_model = net\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {} / {}\".format(epoch, epochs))\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                optimizer = get_optimizer(net)\n",
    "                net.train()\n",
    "            else:\n",
    "                net.train(False)\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for img, label in data_loaders.get(phase):\n",
    "                img, label = Variable(img.cuda()), Variable(label.cuda())\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(img)\n",
    "                preds = torch.ge(outputs.data, 0.5).resize_(label.data.size())\n",
    "                loss = criterion(outputs, label)\n",
    "                if phase =='train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += (preds.float() == label.float()).sum().item()\n",
    "            epoch_loss = running_loss / data_loaders[phase].num\n",
    "            epoch_acc = running_corrects / data_loaders[phase].num\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(net.state_dict(), weight_file)\n",
    "                best_model = net\n",
    "    print('Best validation accuracy: {:4f}'.format(best_acc))\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dense201():\n",
    "    net = models.densenet201(pretrained=True)\n",
    "    net.classifier = nn.Sequential(nn.Linear(net.classifier.in_features, 1), nn.Sigmoid())\n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net():\n",
    "    net = get_dense201()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = get_optimizer(net)\n",
    "    train(net, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(net):\n",
    "    loader = get_data_loader(test_set, training=False, shuffle=False)\n",
    "    preds = []\n",
    "    net.eval()\n",
    "    for i, img in enumerate(loader, 0):\n",
    "        inputs = Variable(img.cuda())\n",
    "        outputs = net(inputs)\n",
    "        pred = outputs.data.cpu().tolist()\n",
    "        for p in pred:\n",
    "            preds.append(p)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(preds, filename):\n",
    "    df = pd.read_csv('sample_submission.csv')\n",
    "    df['invasive'] = preds\n",
    "    print(df.head())\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0356 Acc: 0.8584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([9])) that is different to the input size (torch.Size([9, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.0193 Acc: 0.9107\n",
      "Epoch 1 / 5\n",
      "train Loss: 0.0251 Acc: 0.9069\n",
      "valid Loss: 0.0232 Acc: 0.9477\n",
      "Epoch 2 / 5\n",
      "train Loss: 0.0404 Acc: 0.8671\n",
      "valid Loss: 0.0222 Acc: 0.9020\n",
      "Epoch 3 / 5\n",
      "train Loss: 0.0342 Acc: 0.8731\n",
      "valid Loss: 1.7165 Acc: 0.3725\n",
      "Epoch 4 / 5\n",
      "train Loss: 0.0948 Acc: 0.6629\n",
      "valid Loss: 0.1989 Acc: 0.6710\n",
      "Best validation accuracy: 0.947712\n"
     ]
    }
   ],
   "source": [
    "train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   name  invasive\n",
      "0     1  1.000000\n",
      "1     2  0.038848\n",
      "2     3  0.122464\n",
      "3     4  0.034812\n",
      "4     5  1.000000\n"
     ]
    }
   ],
   "source": [
    "net = get_dense201()\n",
    "net.load_state_dict(torch.load(weight_file))\n",
    "preds = predict(net)\n",
    "submit(preds, 'submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
